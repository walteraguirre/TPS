## Entrenamiento del sistema de recomendaci칩n con una clase `FiltroColaborativo`

Se implement칩 una clase llamada `FiltroColaborativo`, que encapsula todo el comportamiento necesario para entrenar y utilizar un sistema de recomendaci칩n basado en **filtrado colaborativo** mediante **factorizaci칩n matricial** con **descenso por gradiente y regularizaci칩n L2**.

La idea central es aproximar la matriz de calificaciones $ Y $ como el producto de dos matrices latentes de menor dimensi칩n:

$$
Y \approx X \Theta^\top
$$

donde:
- $ X \in \mathbb{R}^{n_{\text{items}} \times k} $ es la matriz de embeddings de 칤tems (pel칤culas).
- $ \Theta \in \mathbb{R}^{n_{\text{usuarios}} \times k} $ es la matriz de embeddings de usuarios.
- $ k $ es la dimensi칩n del espacio latente.

---

### 游빔 Estructura de la clase

La clase est치 compuesta por tres m칠todos principales:

### 1. `__init__(...)`  
Inicializa el modelo con los siguientes hiperpar치metros:
- `k`: dimensi칩n del espacio latente (embedding size).
- `lambda_reg`: coeficiente de regularizaci칩n L2.
- `lr`: tasa de aprendizaje.
- `num_iter`: n칰mero de iteraciones de entrenamiento.

Adem치s, define como atributos internos:
- `X`: matriz de embeddings de 칤tems (inicializada en el entrenamiento).
- `Theta`: matriz de embeddings de usuarios.
- `errores`: lista con la evoluci칩n del error a lo largo del entrenamiento.

---

### 2. `entrenar(Y)`  
Este m칠todo realiza el entrenamiento del modelo, recibiendo como entrada una matriz `Y` de calificaciones (donde los ceros representan valores ausentes). El proceso se desarrolla en varias etapas:

#### Etapas del entrenamiento:

- **Inicializaci칩n aleatoria**  
  Se inicializan las matrices `X` y `Theta` con valores aleatorios peque침os provenientes de una distribuci칩n normal.

- **M치scara de observaci칩n**  
  Se genera una m치scara booleana `mask` que indica d칩nde hay calificaciones reales en `Y`.

- **Bucle de optimizaci칩n**  
  Durante `num_iter` iteraciones:
  
  - Se calcula la matriz de predicciones:
    $$
    \hat{Y} = X \Theta^\top
    $$
  
  - Se calcula el **error observado**, aplicando la m치scara para ignorar entradas ausentes:
    $$
    error = (Y - \hat{Y}) \odot mask
    $$

  - Se computan los **gradientes** del error regularizado respecto a `X` y `Theta`.

  - Se actualizan los par치metros usando descenso por gradiente:
    $$
    X \leftarrow X - \eta \cdot \nabla_X
    \quad\text{y}\quad
    \Theta \leftarrow \Theta - \eta \cdot \nabla_\Theta
    $$

  - Se eval칰a el **riesgo regularizado emp칤rico**:
    $$
    J = \frac{1}{2} \sum_{i,j: y_{ij}>0} (y_{ij} - \theta_j^\top x_i)^2 + \frac{\lambda}{2} \left( \|X\|^2 + \|\Theta\|^2 \right)
    $$

  - Este valor se guarda en `self.errores` para monitorear la convergencia del algoritmo.

---

### 3. `predecir(usuario_idx=None)`  
Devuelve la matriz completa de predicciones $ \hat{Y} = X \Theta^\top $, o solo la columna correspondiente a un usuario si se especifica su 칤ndice.

Esto permite recuperar las predicciones personalizadas para un usuario y ordenarlas para recomendarle las pel칤culas mejor valoradas que a칰n no haya visto.

---

### 4. `graficar_error()`  
Este m칠todo grafica la evoluci칩n del riesgo regularizado a lo largo de las iteraciones de entrenamiento. Es 칰til para verificar si el modelo converge y ajustar hiperpar치metros en caso contrario.

---

### 游늷 Ejemplo de uso

Una vez cargada y preprocesada la matriz de calificaciones desde el `DataFrame`, se entrena el modelo de la siguiente forma:

```python
Y = df_actualizado.drop(columns=["Name"]).values.astype(float)

modelo_filtro = FiltroColaborativo(k=10, lambda_reg=10, lr=1e-3, num_iter=2000)
modelo_filtro.entrenar(Y)

modelo_filtro.graficar_error()
